{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "!sudo apt-get install -y fonts-nanum\n",
    "!sudo fc-cache -fv\n",
    "!rm ~/.cache/matplotlib -rf\n",
    "\n"
   ],
   "metadata": {
    "id": "EW_pWjLLUmqL"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qlfveXvVbqit",
    "outputId": "c97c716e-a829-4d03-dc90-b4d986f1530b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.rc('font', family='NanumBarunGothic')"
   ],
   "metadata": {
    "id": "zUSk70kbUpIS"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7U8ibyg3dBnC"
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __int__(self):\n",
    "        pass\n",
    "\n",
    "    def getFindDegList(self):\n",
    "        return [\n",
    "            [4, 3, 2],\n",
    "            [3, 2, 1],\n",
    "\n",
    "            [8, 7, 6],\n",
    "            [7, 6, 5],\n",
    "            [6, 5, 0],\n",
    "\n",
    "            [12, 11, 10],\n",
    "            [11, 10, 9],\n",
    "\n",
    "            [16, 15, 14],\n",
    "            [15, 14, 13],\n",
    "\n",
    "            [20, 19, 18],\n",
    "            [19, 18, 17],\n",
    "            [18, 17, 0],\n",
    "\n",
    "            [6, 5, 9],\n",
    "            [10, 9, 5],\n",
    "\n",
    "            [14, 13, 9],\n",
    "            [18, 17, 13],\n",
    "        ]\n",
    "\n",
    "    def imageGetDeg(self, hand_landmarks, label):\n",
    "        degList = []\n",
    "\n",
    "        for n, i in enumerate(self.getFindDegList()):\n",
    "            p1 = hand_landmarks.landmark[i[0]]\n",
    "            p2 = hand_landmarks.landmark[i[1]]\n",
    "            p3 = hand_landmarks.landmark[i[2]]\n",
    "\n",
    "            deg = self.getDeg(p1, p2, p3)\n",
    "\n",
    "            degList.append(deg)\n",
    "        degList.append(label)\n",
    "\n",
    "        return degList\n",
    "\n",
    "    def getDeg(self, p1, p2, p3):\n",
    "        A = self.landmarkToNparray(p1)\n",
    "        B = self.landmarkToNparray(p2)\n",
    "        C = self.landmarkToNparray(p3)\n",
    "\n",
    "        AB = B - A\n",
    "        BC = C - B\n",
    "\n",
    "        dot = np.dot(AB, BC)\n",
    "\n",
    "        normAB = np.linalg.norm(AB)\n",
    "        normBC = np.linalg.norm(BC)\n",
    "        angle_rad = np.arccos(dot / (normAB * normBC))\n",
    "\n",
    "        angle_deg = np.degrees(angle_rad)\n",
    "\n",
    "        return min(angle_deg, 180 - angle_deg)\n",
    "\n",
    "\n",
    "    def landmarkToNparray(self, landmark):\n",
    "        array = np.array([landmark.x, landmark.y, landmark.z])\n",
    "        return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XbOKVKw0banc"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data_path = \"/content/drive/Shareddrives/2023 인공지능 모델링 프로젝트/data/data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "id": "bp457IIzcq38",
    "outputId": "e04ed509-e65a-437f-a0a7-d162b777b88e"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               1          2         3          4          5          6  \\\n",
       "0       4.180266  39.382984  5.845003   3.559500  28.238728   4.531369   \n",
       "1      18.695793  40.142249  5.094160   2.129227  28.513457   3.421851   \n",
       "2       7.804296  54.164513  8.602587   5.456619  34.294114   3.066038   \n",
       "3       2.160568  43.060328  6.647380   4.201977  36.604253   7.063699   \n",
       "4      12.566229  35.548996  4.847611   2.859979  15.109210   2.469584   \n",
       "...          ...        ...       ...        ...        ...        ...   \n",
       "12471  12.062862  33.842467  4.310661   9.316777  16.311611  12.246170   \n",
       "12472  11.239955  33.241404  3.895593   8.827879  15.801240  11.037895   \n",
       "12473  11.368164  33.332250  4.217700   9.166557  17.795801  12.063681   \n",
       "12474  12.437373  32.109936  4.114565  10.520655  16.405797  13.408117   \n",
       "12475  12.437799  31.977395  4.028698  10.985869  16.608168  14.426903   \n",
       "\n",
       "               7          8          9         10         11         12  \\\n",
       "0       2.158596   4.031397   2.181086   5.231499   4.659680  26.895114   \n",
       "1       0.085816   3.258343   1.384106   4.606371   7.318714  35.356139   \n",
       "2       5.421571   1.401004   5.327053   3.663637   2.119198  40.007747   \n",
       "3       3.420155   6.960085   1.958317   6.711954   4.480131  33.887779   \n",
       "4       2.271303   3.453879   0.789902   5.352952   8.172017  33.642691   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "12471   8.050897  24.039373  83.875319  18.020798  65.397081  73.548910   \n",
       "12472   8.003798  24.860819  80.900228  20.236443  59.400214  79.570144   \n",
       "12473   9.860264  26.337273  82.696618  21.601804  61.602809  76.894048   \n",
       "12474  10.517554  26.212750  79.445150  20.669702  60.106470  75.528107   \n",
       "12475   9.909031  26.955345  79.797754  22.420372  60.383468  75.706455   \n",
       "\n",
       "              13         14         15         16  label  \n",
       "0      85.025627  89.980678  81.105623  80.069341    0.0  \n",
       "1      87.473216  87.526406  76.409421  72.425620    0.0  \n",
       "2      83.702541  89.434963  77.388172  66.223779    0.0  \n",
       "3      81.699394  87.509653  80.008598  70.512175    0.0  \n",
       "4      75.726345  81.140176  73.112035  68.342777    0.0  \n",
       "...          ...        ...        ...        ...    ...  \n",
       "12471  63.128760  86.054761  85.323911  73.390631    2.0  \n",
       "12472  62.883336  84.227522  84.619465  74.187763    2.0  \n",
       "12473  61.847763  83.817994  82.206835  71.258504    2.0  \n",
       "12474  60.328060  84.513516  82.791716  71.767805    2.0  \n",
       "12475  61.078836  82.984291  83.102720  72.064302    2.0  \n",
       "\n",
       "[12476 rows x 17 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-21f695f9-585a-4dec-8cda-2298d607a003\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.180266</td>\n",
       "      <td>39.382984</td>\n",
       "      <td>5.845003</td>\n",
       "      <td>3.559500</td>\n",
       "      <td>28.238728</td>\n",
       "      <td>4.531369</td>\n",
       "      <td>2.158596</td>\n",
       "      <td>4.031397</td>\n",
       "      <td>2.181086</td>\n",
       "      <td>5.231499</td>\n",
       "      <td>4.659680</td>\n",
       "      <td>26.895114</td>\n",
       "      <td>85.025627</td>\n",
       "      <td>89.980678</td>\n",
       "      <td>81.105623</td>\n",
       "      <td>80.069341</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.695793</td>\n",
       "      <td>40.142249</td>\n",
       "      <td>5.094160</td>\n",
       "      <td>2.129227</td>\n",
       "      <td>28.513457</td>\n",
       "      <td>3.421851</td>\n",
       "      <td>0.085816</td>\n",
       "      <td>3.258343</td>\n",
       "      <td>1.384106</td>\n",
       "      <td>4.606371</td>\n",
       "      <td>7.318714</td>\n",
       "      <td>35.356139</td>\n",
       "      <td>87.473216</td>\n",
       "      <td>87.526406</td>\n",
       "      <td>76.409421</td>\n",
       "      <td>72.425620</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.804296</td>\n",
       "      <td>54.164513</td>\n",
       "      <td>8.602587</td>\n",
       "      <td>5.456619</td>\n",
       "      <td>34.294114</td>\n",
       "      <td>3.066038</td>\n",
       "      <td>5.421571</td>\n",
       "      <td>1.401004</td>\n",
       "      <td>5.327053</td>\n",
       "      <td>3.663637</td>\n",
       "      <td>2.119198</td>\n",
       "      <td>40.007747</td>\n",
       "      <td>83.702541</td>\n",
       "      <td>89.434963</td>\n",
       "      <td>77.388172</td>\n",
       "      <td>66.223779</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.160568</td>\n",
       "      <td>43.060328</td>\n",
       "      <td>6.647380</td>\n",
       "      <td>4.201977</td>\n",
       "      <td>36.604253</td>\n",
       "      <td>7.063699</td>\n",
       "      <td>3.420155</td>\n",
       "      <td>6.960085</td>\n",
       "      <td>1.958317</td>\n",
       "      <td>6.711954</td>\n",
       "      <td>4.480131</td>\n",
       "      <td>33.887779</td>\n",
       "      <td>81.699394</td>\n",
       "      <td>87.509653</td>\n",
       "      <td>80.008598</td>\n",
       "      <td>70.512175</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.566229</td>\n",
       "      <td>35.548996</td>\n",
       "      <td>4.847611</td>\n",
       "      <td>2.859979</td>\n",
       "      <td>15.109210</td>\n",
       "      <td>2.469584</td>\n",
       "      <td>2.271303</td>\n",
       "      <td>3.453879</td>\n",
       "      <td>0.789902</td>\n",
       "      <td>5.352952</td>\n",
       "      <td>8.172017</td>\n",
       "      <td>33.642691</td>\n",
       "      <td>75.726345</td>\n",
       "      <td>81.140176</td>\n",
       "      <td>73.112035</td>\n",
       "      <td>68.342777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>12.062862</td>\n",
       "      <td>33.842467</td>\n",
       "      <td>4.310661</td>\n",
       "      <td>9.316777</td>\n",
       "      <td>16.311611</td>\n",
       "      <td>12.246170</td>\n",
       "      <td>8.050897</td>\n",
       "      <td>24.039373</td>\n",
       "      <td>83.875319</td>\n",
       "      <td>18.020798</td>\n",
       "      <td>65.397081</td>\n",
       "      <td>73.548910</td>\n",
       "      <td>63.128760</td>\n",
       "      <td>86.054761</td>\n",
       "      <td>85.323911</td>\n",
       "      <td>73.390631</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12472</th>\n",
       "      <td>11.239955</td>\n",
       "      <td>33.241404</td>\n",
       "      <td>3.895593</td>\n",
       "      <td>8.827879</td>\n",
       "      <td>15.801240</td>\n",
       "      <td>11.037895</td>\n",
       "      <td>8.003798</td>\n",
       "      <td>24.860819</td>\n",
       "      <td>80.900228</td>\n",
       "      <td>20.236443</td>\n",
       "      <td>59.400214</td>\n",
       "      <td>79.570144</td>\n",
       "      <td>62.883336</td>\n",
       "      <td>84.227522</td>\n",
       "      <td>84.619465</td>\n",
       "      <td>74.187763</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>11.368164</td>\n",
       "      <td>33.332250</td>\n",
       "      <td>4.217700</td>\n",
       "      <td>9.166557</td>\n",
       "      <td>17.795801</td>\n",
       "      <td>12.063681</td>\n",
       "      <td>9.860264</td>\n",
       "      <td>26.337273</td>\n",
       "      <td>82.696618</td>\n",
       "      <td>21.601804</td>\n",
       "      <td>61.602809</td>\n",
       "      <td>76.894048</td>\n",
       "      <td>61.847763</td>\n",
       "      <td>83.817994</td>\n",
       "      <td>82.206835</td>\n",
       "      <td>71.258504</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>12.437373</td>\n",
       "      <td>32.109936</td>\n",
       "      <td>4.114565</td>\n",
       "      <td>10.520655</td>\n",
       "      <td>16.405797</td>\n",
       "      <td>13.408117</td>\n",
       "      <td>10.517554</td>\n",
       "      <td>26.212750</td>\n",
       "      <td>79.445150</td>\n",
       "      <td>20.669702</td>\n",
       "      <td>60.106470</td>\n",
       "      <td>75.528107</td>\n",
       "      <td>60.328060</td>\n",
       "      <td>84.513516</td>\n",
       "      <td>82.791716</td>\n",
       "      <td>71.767805</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12475</th>\n",
       "      <td>12.437799</td>\n",
       "      <td>31.977395</td>\n",
       "      <td>4.028698</td>\n",
       "      <td>10.985869</td>\n",
       "      <td>16.608168</td>\n",
       "      <td>14.426903</td>\n",
       "      <td>9.909031</td>\n",
       "      <td>26.955345</td>\n",
       "      <td>79.797754</td>\n",
       "      <td>22.420372</td>\n",
       "      <td>60.383468</td>\n",
       "      <td>75.706455</td>\n",
       "      <td>61.078836</td>\n",
       "      <td>82.984291</td>\n",
       "      <td>83.102720</td>\n",
       "      <td>72.064302</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12476 rows × 17 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21f695f9-585a-4dec-8cda-2298d607a003')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-21f695f9-585a-4dec-8cda-2298d607a003 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-21f695f9-585a-4dec-8cda-2298d607a003');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "df = pd.read_csv(data_path)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-7HeMtDic5-I",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 488
    },
    "outputId": "358a67c2-5dc0-4256-dd5a-6f98fc1f1fb2"
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               1          2         3          4          5          6  \\\n",
       "0       4.180266  39.382984  5.845003   3.559500  28.238728   4.531369   \n",
       "1      18.695793  40.142249  5.094160   2.129227  28.513457   3.421851   \n",
       "2       7.804296  54.164513  8.602587   5.456619  34.294114   3.066038   \n",
       "3       2.160568  43.060328  6.647380   4.201977  36.604253   7.063699   \n",
       "4      12.566229  35.548996  4.847611   2.859979  15.109210   2.469584   \n",
       "...          ...        ...       ...        ...        ...        ...   \n",
       "12471  12.062862  33.842467  4.310661   9.316777  16.311611  12.246170   \n",
       "12472  11.239955  33.241404  3.895593   8.827879  15.801240  11.037895   \n",
       "12473  11.368164  33.332250  4.217700   9.166557  17.795801  12.063681   \n",
       "12474  12.437373  32.109936  4.114565  10.520655  16.405797  13.408117   \n",
       "12475  12.437799  31.977395  4.028698  10.985869  16.608168  14.426903   \n",
       "\n",
       "               7          8          9         10         11         12  \\\n",
       "0       2.158596   4.031397   2.181086   5.231499   4.659680  26.895114   \n",
       "1       0.085816   3.258343   1.384106   4.606371   7.318714  35.356139   \n",
       "2       5.421571   1.401004   5.327053   3.663637   2.119198  40.007747   \n",
       "3       3.420155   6.960085   1.958317   6.711954   4.480131  33.887779   \n",
       "4       2.271303   3.453879   0.789902   5.352952   8.172017  33.642691   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "12471   8.050897  24.039373  83.875319  18.020798  65.397081  73.548910   \n",
       "12472   8.003798  24.860819  80.900228  20.236443  59.400214  79.570144   \n",
       "12473   9.860264  26.337273  82.696618  21.601804  61.602809  76.894048   \n",
       "12474  10.517554  26.212750  79.445150  20.669702  60.106470  75.528107   \n",
       "12475   9.909031  26.955345  79.797754  22.420372  60.383468  75.706455   \n",
       "\n",
       "              13         14         15         16  label_0.0  label_1.0  \\\n",
       "0      85.025627  89.980678  81.105623  80.069341          1          0   \n",
       "1      87.473216  87.526406  76.409421  72.425620          1          0   \n",
       "2      83.702541  89.434963  77.388172  66.223779          1          0   \n",
       "3      81.699394  87.509653  80.008598  70.512175          1          0   \n",
       "4      75.726345  81.140176  73.112035  68.342777          1          0   \n",
       "...          ...        ...        ...        ...        ...        ...   \n",
       "12471  63.128760  86.054761  85.323911  73.390631          0          0   \n",
       "12472  62.883336  84.227522  84.619465  74.187763          0          0   \n",
       "12473  61.847763  83.817994  82.206835  71.258504          0          0   \n",
       "12474  60.328060  84.513516  82.791716  71.767805          0          0   \n",
       "12475  61.078836  82.984291  83.102720  72.064302          0          0   \n",
       "\n",
       "       label_2.0  \n",
       "0              0  \n",
       "1              0  \n",
       "2              0  \n",
       "3              0  \n",
       "4              0  \n",
       "...          ...  \n",
       "12471          1  \n",
       "12472          1  \n",
       "12473          1  \n",
       "12474          1  \n",
       "12475          1  \n",
       "\n",
       "[12476 rows x 19 columns]"
      ],
      "text/html": [
       "\n",
       "  <div id=\"df-a6184f7b-8978-46ca-a42a-3299188ac504\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>label_0.0</th>\n",
       "      <th>label_1.0</th>\n",
       "      <th>label_2.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.180266</td>\n",
       "      <td>39.382984</td>\n",
       "      <td>5.845003</td>\n",
       "      <td>3.559500</td>\n",
       "      <td>28.238728</td>\n",
       "      <td>4.531369</td>\n",
       "      <td>2.158596</td>\n",
       "      <td>4.031397</td>\n",
       "      <td>2.181086</td>\n",
       "      <td>5.231499</td>\n",
       "      <td>4.659680</td>\n",
       "      <td>26.895114</td>\n",
       "      <td>85.025627</td>\n",
       "      <td>89.980678</td>\n",
       "      <td>81.105623</td>\n",
       "      <td>80.069341</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18.695793</td>\n",
       "      <td>40.142249</td>\n",
       "      <td>5.094160</td>\n",
       "      <td>2.129227</td>\n",
       "      <td>28.513457</td>\n",
       "      <td>3.421851</td>\n",
       "      <td>0.085816</td>\n",
       "      <td>3.258343</td>\n",
       "      <td>1.384106</td>\n",
       "      <td>4.606371</td>\n",
       "      <td>7.318714</td>\n",
       "      <td>35.356139</td>\n",
       "      <td>87.473216</td>\n",
       "      <td>87.526406</td>\n",
       "      <td>76.409421</td>\n",
       "      <td>72.425620</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.804296</td>\n",
       "      <td>54.164513</td>\n",
       "      <td>8.602587</td>\n",
       "      <td>5.456619</td>\n",
       "      <td>34.294114</td>\n",
       "      <td>3.066038</td>\n",
       "      <td>5.421571</td>\n",
       "      <td>1.401004</td>\n",
       "      <td>5.327053</td>\n",
       "      <td>3.663637</td>\n",
       "      <td>2.119198</td>\n",
       "      <td>40.007747</td>\n",
       "      <td>83.702541</td>\n",
       "      <td>89.434963</td>\n",
       "      <td>77.388172</td>\n",
       "      <td>66.223779</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.160568</td>\n",
       "      <td>43.060328</td>\n",
       "      <td>6.647380</td>\n",
       "      <td>4.201977</td>\n",
       "      <td>36.604253</td>\n",
       "      <td>7.063699</td>\n",
       "      <td>3.420155</td>\n",
       "      <td>6.960085</td>\n",
       "      <td>1.958317</td>\n",
       "      <td>6.711954</td>\n",
       "      <td>4.480131</td>\n",
       "      <td>33.887779</td>\n",
       "      <td>81.699394</td>\n",
       "      <td>87.509653</td>\n",
       "      <td>80.008598</td>\n",
       "      <td>70.512175</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.566229</td>\n",
       "      <td>35.548996</td>\n",
       "      <td>4.847611</td>\n",
       "      <td>2.859979</td>\n",
       "      <td>15.109210</td>\n",
       "      <td>2.469584</td>\n",
       "      <td>2.271303</td>\n",
       "      <td>3.453879</td>\n",
       "      <td>0.789902</td>\n",
       "      <td>5.352952</td>\n",
       "      <td>8.172017</td>\n",
       "      <td>33.642691</td>\n",
       "      <td>75.726345</td>\n",
       "      <td>81.140176</td>\n",
       "      <td>73.112035</td>\n",
       "      <td>68.342777</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12471</th>\n",
       "      <td>12.062862</td>\n",
       "      <td>33.842467</td>\n",
       "      <td>4.310661</td>\n",
       "      <td>9.316777</td>\n",
       "      <td>16.311611</td>\n",
       "      <td>12.246170</td>\n",
       "      <td>8.050897</td>\n",
       "      <td>24.039373</td>\n",
       "      <td>83.875319</td>\n",
       "      <td>18.020798</td>\n",
       "      <td>65.397081</td>\n",
       "      <td>73.548910</td>\n",
       "      <td>63.128760</td>\n",
       "      <td>86.054761</td>\n",
       "      <td>85.323911</td>\n",
       "      <td>73.390631</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12472</th>\n",
       "      <td>11.239955</td>\n",
       "      <td>33.241404</td>\n",
       "      <td>3.895593</td>\n",
       "      <td>8.827879</td>\n",
       "      <td>15.801240</td>\n",
       "      <td>11.037895</td>\n",
       "      <td>8.003798</td>\n",
       "      <td>24.860819</td>\n",
       "      <td>80.900228</td>\n",
       "      <td>20.236443</td>\n",
       "      <td>59.400214</td>\n",
       "      <td>79.570144</td>\n",
       "      <td>62.883336</td>\n",
       "      <td>84.227522</td>\n",
       "      <td>84.619465</td>\n",
       "      <td>74.187763</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12473</th>\n",
       "      <td>11.368164</td>\n",
       "      <td>33.332250</td>\n",
       "      <td>4.217700</td>\n",
       "      <td>9.166557</td>\n",
       "      <td>17.795801</td>\n",
       "      <td>12.063681</td>\n",
       "      <td>9.860264</td>\n",
       "      <td>26.337273</td>\n",
       "      <td>82.696618</td>\n",
       "      <td>21.601804</td>\n",
       "      <td>61.602809</td>\n",
       "      <td>76.894048</td>\n",
       "      <td>61.847763</td>\n",
       "      <td>83.817994</td>\n",
       "      <td>82.206835</td>\n",
       "      <td>71.258504</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12474</th>\n",
       "      <td>12.437373</td>\n",
       "      <td>32.109936</td>\n",
       "      <td>4.114565</td>\n",
       "      <td>10.520655</td>\n",
       "      <td>16.405797</td>\n",
       "      <td>13.408117</td>\n",
       "      <td>10.517554</td>\n",
       "      <td>26.212750</td>\n",
       "      <td>79.445150</td>\n",
       "      <td>20.669702</td>\n",
       "      <td>60.106470</td>\n",
       "      <td>75.528107</td>\n",
       "      <td>60.328060</td>\n",
       "      <td>84.513516</td>\n",
       "      <td>82.791716</td>\n",
       "      <td>71.767805</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12475</th>\n",
       "      <td>12.437799</td>\n",
       "      <td>31.977395</td>\n",
       "      <td>4.028698</td>\n",
       "      <td>10.985869</td>\n",
       "      <td>16.608168</td>\n",
       "      <td>14.426903</td>\n",
       "      <td>9.909031</td>\n",
       "      <td>26.955345</td>\n",
       "      <td>79.797754</td>\n",
       "      <td>22.420372</td>\n",
       "      <td>60.383468</td>\n",
       "      <td>75.706455</td>\n",
       "      <td>61.078836</td>\n",
       "      <td>82.984291</td>\n",
       "      <td>83.102720</td>\n",
       "      <td>72.064302</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12476 rows × 19 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a6184f7b-8978-46ca-a42a-3299188ac504')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-a6184f7b-8978-46ca-a42a-3299188ac504 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-a6184f7b-8978-46ca-a42a-3299188ac504');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "data_df = pd.get_dummies(df, columns = ['label']) # 원핫 인코딩\n",
    "data_df"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "data_y = data_df[[\"label_0.0\",\t\"label_1.0\",\t\"label_2.0\"]].to_numpy()\n",
    "data_x = data_df.drop([\"label_0.0\",\t\"label_1.0\",\t\"label_2.0\"], axis = 1).to_numpy()\n",
    "\n",
    "data_x.shape, data_y.shape"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q9XF_7ZN4iGF",
    "outputId": "bf722675-bc6e-464a-a6aa-0a0b75f8db7e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((12476, 16), (12476, 3))"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(data_x, data_y, test_size=0.3, random_state=777, shuffle=True)\n",
    "\n",
    "print(train_x.shape, test_x.shape)\n",
    "print(train_y.shape, test_y.shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z20zi5_841u5",
    "outputId": "c9ace785-5559-42f5-ef20-37ececaf1682"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(8733, 16) (3743, 16)\n",
      "(8733, 3) (3743, 3)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(sum(train_y[:, 0]))\n",
    "print(sum(train_y[:, 1]))\n",
    "print(sum(train_y[:, 2]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(sum(test_y[:, 0]))\n",
    "print(sum(test_y[:, 1]))\n",
    "print(sum(test_y[:, 2]))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pp9lAmIpAtsC",
    "outputId": "3a895022-a356-4b20-dde8-967cde0eaba7"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "3000\n",
      "2705\n",
      "3028\n",
      "\n",
      "1288\n",
      "1225\n",
      "1230\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model1 = Sequential()\n",
    "\n",
    "model1.add(\n",
    "    Dense(30, input_dim = 16, activation=\"relu\", name = \"Hidden_1\")\n",
    ")\n",
    "\n",
    "model1.add(\n",
    "    Dense(12, activation=\"relu\", name = \"Hidden_2\")\n",
    ")\n",
    "\n",
    "model1.add(\n",
    "    Dense(8, activation=\"relu\", name = \"Hidden_3\")\n",
    ")\n",
    "\n",
    "model1.add(\n",
    "    Dense(3, activation=\"softmax\", name = \"Output\")\n",
    ")\n",
    "\n",
    "model1.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YmfIkninB6WM",
    "outputId": "756ef6d9-07a3-47f9-e18e-4c160f9edbfa"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden_1 (Dense)            (None, 30)                510       \n",
      "                                                                 \n",
      " Hidden_2 (Dense)            (None, 12)                372       \n",
      "                                                                 \n",
      " Hidden_3 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,013\n",
      "Trainable params: 1,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model1.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_model_1 = model1.fit(train_x, train_y, epochs=100, batch_size=500, validation_split=0.25)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9t27vytKCBpu",
    "outputId": "c57b3055-75b8-4f14-b1a6-cde1c9b642df"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "14/14 [==============================] - 1s 11ms/step - loss: 0.3677 - accuracy: 0.6545 - val_loss: 0.3734 - val_accuracy: 0.6465\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3664 - accuracy: 0.6548 - val_loss: 0.3727 - val_accuracy: 0.6456\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3657 - accuracy: 0.6529 - val_loss: 0.3724 - val_accuracy: 0.6456\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3652 - accuracy: 0.6485 - val_loss: 0.3716 - val_accuracy: 0.6534\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3644 - accuracy: 0.6545 - val_loss: 0.3717 - val_accuracy: 0.6538\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3637 - accuracy: 0.6531 - val_loss: 0.3707 - val_accuracy: 0.6451\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3638 - accuracy: 0.6551 - val_loss: 0.3705 - val_accuracy: 0.6442\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3628 - accuracy: 0.6548 - val_loss: 0.3698 - val_accuracy: 0.6456\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3623 - accuracy: 0.6546 - val_loss: 0.3696 - val_accuracy: 0.6447\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3616 - accuracy: 0.6554 - val_loss: 0.3683 - val_accuracy: 0.6456\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3610 - accuracy: 0.6543 - val_loss: 0.3680 - val_accuracy: 0.6461\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.6552 - val_loss: 0.3677 - val_accuracy: 0.6456\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3599 - accuracy: 0.6551 - val_loss: 0.3673 - val_accuracy: 0.6451\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3596 - accuracy: 0.6554 - val_loss: 0.3681 - val_accuracy: 0.6442\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.6558 - val_loss: 0.3662 - val_accuracy: 0.6451\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3588 - accuracy: 0.6557 - val_loss: 0.3655 - val_accuracy: 0.6470\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.6580 - val_loss: 0.3665 - val_accuracy: 0.6447\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3584 - accuracy: 0.6563 - val_loss: 0.3650 - val_accuracy: 0.6479\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3575 - accuracy: 0.6578 - val_loss: 0.3659 - val_accuracy: 0.6470\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3573 - accuracy: 0.6586 - val_loss: 0.3648 - val_accuracy: 0.6470\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3570 - accuracy: 0.6575 - val_loss: 0.3633 - val_accuracy: 0.6488\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3582 - accuracy: 0.6555 - val_loss: 0.3626 - val_accuracy: 0.6484\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.3568 - accuracy: 0.6677 - val_loss: 0.3613 - val_accuracy: 0.6717\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3537 - accuracy: 0.6800 - val_loss: 0.3604 - val_accuracy: 0.6708\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3524 - accuracy: 0.6870 - val_loss: 0.3549 - val_accuracy: 0.7340\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8305 - val_loss: 0.3329 - val_accuracy: 0.8805\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.9227 - val_loss: 0.3073 - val_accuracy: 0.9615\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.9693 - val_loss: 0.2856 - val_accuracy: 0.9776\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.9797 - val_loss: 0.2679 - val_accuracy: 0.9826\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.2516 - accuracy: 0.9838 - val_loss: 0.2452 - val_accuracy: 0.9895\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2266 - accuracy: 0.9870 - val_loss: 0.2168 - val_accuracy: 0.9886\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.2006 - accuracy: 0.9895 - val_loss: 0.1913 - val_accuracy: 0.9904\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1771 - accuracy: 0.9899 - val_loss: 0.1634 - val_accuracy: 0.9899\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1452 - accuracy: 0.9905 - val_loss: 0.1333 - val_accuracy: 0.9908\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1197 - accuracy: 0.9916 - val_loss: 0.1134 - val_accuracy: 0.9927\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.1031 - accuracy: 0.9913 - val_loss: 0.1009 - val_accuracy: 0.9918\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0918 - accuracy: 0.9918 - val_loss: 0.0896 - val_accuracy: 0.9908\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0802 - accuracy: 0.9924 - val_loss: 0.0806 - val_accuracy: 0.9931\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0748 - accuracy: 0.9921 - val_loss: 0.0718 - val_accuracy: 0.9927\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0654 - accuracy: 0.9930 - val_loss: 0.0653 - val_accuracy: 0.9936\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0600 - accuracy: 0.9921 - val_loss: 0.0614 - val_accuracy: 0.9927\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0557 - accuracy: 0.9925 - val_loss: 0.0607 - val_accuracy: 0.9899\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0515 - accuracy: 0.9928 - val_loss: 0.0505 - val_accuracy: 0.9940\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0452 - accuracy: 0.9933 - val_loss: 0.0462 - val_accuracy: 0.9936\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0409 - accuracy: 0.9937 - val_loss: 0.0417 - val_accuracy: 0.9945\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0376 - accuracy: 0.9939 - val_loss: 0.0393 - val_accuracy: 0.9940\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0345 - accuracy: 0.9945 - val_loss: 0.0365 - val_accuracy: 0.9940\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0336 - accuracy: 0.9936 - val_loss: 0.0337 - val_accuracy: 0.9945\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0304 - accuracy: 0.9939 - val_loss: 0.0352 - val_accuracy: 0.9931\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0279 - accuracy: 0.9947 - val_loss: 0.0340 - val_accuracy: 0.9922\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0273 - accuracy: 0.9934 - val_loss: 0.0286 - val_accuracy: 0.9936\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0247 - accuracy: 0.9948 - val_loss: 0.0271 - val_accuracy: 0.9945\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0232 - accuracy: 0.9954 - val_loss: 0.0262 - val_accuracy: 0.9950\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0227 - accuracy: 0.9954 - val_loss: 0.0265 - val_accuracy: 0.9940\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0229 - accuracy: 0.9947 - val_loss: 0.0266 - val_accuracy: 0.9940\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0207 - accuracy: 0.9950 - val_loss: 0.0230 - val_accuracy: 0.9954\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9950 - val_loss: 0.0218 - val_accuracy: 0.9954\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0198 - accuracy: 0.9948 - val_loss: 0.0235 - val_accuracy: 0.9927\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0182 - accuracy: 0.9957 - val_loss: 0.0213 - val_accuracy: 0.9950\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0175 - accuracy: 0.9959 - val_loss: 0.0216 - val_accuracy: 0.9950\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.0164 - accuracy: 0.9956 - val_loss: 0.0206 - val_accuracy: 0.9945\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0163 - accuracy: 0.9960 - val_loss: 0.0200 - val_accuracy: 0.9954\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 0.0196 - val_accuracy: 0.9954\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0156 - accuracy: 0.9954 - val_loss: 0.0191 - val_accuracy: 0.9959\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0152 - accuracy: 0.9957 - val_loss: 0.0188 - val_accuracy: 0.9945\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0151 - accuracy: 0.9959 - val_loss: 0.0190 - val_accuracy: 0.9950\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0147 - accuracy: 0.9956 - val_loss: 0.0190 - val_accuracy: 0.9940\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0154 - accuracy: 0.9951 - val_loss: 0.0198 - val_accuracy: 0.9954\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0139 - accuracy: 0.9959 - val_loss: 0.0183 - val_accuracy: 0.9959\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0141 - accuracy: 0.9957 - val_loss: 0.0180 - val_accuracy: 0.9950\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0132 - accuracy: 0.9962 - val_loss: 0.0189 - val_accuracy: 0.9959\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0135 - accuracy: 0.9956 - val_loss: 0.0202 - val_accuracy: 0.9945\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0183 - accuracy: 0.9942 - val_loss: 0.0231 - val_accuracy: 0.9927\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0138 - accuracy: 0.9953 - val_loss: 0.0172 - val_accuracy: 0.9963\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0129 - accuracy: 0.9960 - val_loss: 0.0169 - val_accuracy: 0.9963\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0127 - accuracy: 0.9957 - val_loss: 0.0175 - val_accuracy: 0.9950\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0123 - accuracy: 0.9960 - val_loss: 0.0177 - val_accuracy: 0.9945\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0120 - accuracy: 0.9959 - val_loss: 0.0165 - val_accuracy: 0.9954\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0120 - accuracy: 0.9962 - val_loss: 0.0169 - val_accuracy: 0.9945\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0117 - accuracy: 0.9965 - val_loss: 0.0171 - val_accuracy: 0.9945\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0116 - accuracy: 0.9966 - val_loss: 0.0169 - val_accuracy: 0.9950\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0116 - accuracy: 0.9960 - val_loss: 0.0161 - val_accuracy: 0.9950\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0115 - accuracy: 0.9966 - val_loss: 0.0161 - val_accuracy: 0.9945\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0107 - accuracy: 0.9962 - val_loss: 0.0159 - val_accuracy: 0.9963\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9966 - val_loss: 0.0160 - val_accuracy: 0.9959\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0103 - accuracy: 0.9965 - val_loss: 0.0158 - val_accuracy: 0.9954\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0102 - accuracy: 0.9963 - val_loss: 0.0158 - val_accuracy: 0.9959\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0102 - accuracy: 0.9968 - val_loss: 0.0161 - val_accuracy: 0.9963\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0099 - accuracy: 0.9971 - val_loss: 0.0160 - val_accuracy: 0.9954\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0097 - accuracy: 0.9965 - val_loss: 0.0164 - val_accuracy: 0.9954\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0100 - accuracy: 0.9968 - val_loss: 0.0158 - val_accuracy: 0.9959\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0095 - accuracy: 0.9971 - val_loss: 0.0150 - val_accuracy: 0.9968\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0157 - val_accuracy: 0.9959\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0096 - accuracy: 0.9969 - val_loss: 0.0182 - val_accuracy: 0.9931\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0096 - accuracy: 0.9962 - val_loss: 0.0153 - val_accuracy: 0.9963\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.0092 - accuracy: 0.9971 - val_loss: 0.0153 - val_accuracy: 0.9950\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0092 - accuracy: 0.9968 - val_loss: 0.0154 - val_accuracy: 0.9945\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.0094 - accuracy: 0.9969 - val_loss: 0.0171 - val_accuracy: 0.9940\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0088 - accuracy: 0.9969 - val_loss: 0.0150 - val_accuracy: 0.9963\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 3ms/step - loss: 0.0098 - accuracy: 0.9963 - val_loss: 0.0165 - val_accuracy: 0.9950\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "score = model1.evaluate(test_x, test_y)\n",
    "\n",
    "print(f\"모델 1 오차 : {score[0] * 100 : .2f}%\")\n",
    "print(f\"모델 1 정확도 : {score[1] * 100 : .2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoLB8ucKCTm8",
    "outputId": "61c9838e-5638-429c-a69d-08b9316677f9"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "117/117 [==============================] - 0s 1ms/step - loss: 0.0126 - accuracy: 0.9965\n",
      "모델 1 오차 :  1.26%\n",
      "모델 1 정확도 :  99.65%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "model2.add(\n",
    "    Dense(30, input_dim = 16, activation=\"relu\", name = \"Hidden_1\")\n",
    ")\n",
    "\n",
    "model2.add(\n",
    "    Dense(20, activation=\"relu\", name = \"Hidden_2\")\n",
    ")\n",
    "\n",
    "model2.add(\n",
    "    Dense(10, activation=\"relu\", name = \"Hidden_3\")\n",
    ")\n",
    "\n",
    "model2.add(\n",
    "    Dense(5, activation=\"relu\", name = \"Hidden_4\")\n",
    ")\n",
    "\n",
    "model2.add(\n",
    "    Dense(3, activation=\"softmax\", name = \"Output\")\n",
    ")\n",
    "\n",
    "model2.summary()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aP-hCDZpCk0R",
    "outputId": "91943b37-850c-43d8-f41b-18c4c5d80a8b"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " Hidden_1 (Dense)            (None, 30)                510       \n",
      "                                                                 \n",
      " Hidden_2 (Dense)            (None, 20)                620       \n",
      "                                                                 \n",
      " Hidden_3 (Dense)            (None, 10)                210       \n",
      "                                                                 \n",
      " Hidden_4 (Dense)            (None, 5)                 55        \n",
      "                                                                 \n",
      " Output (Dense)              (None, 3)                 18        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,413\n",
      "Trainable params: 1,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "model2.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "\n",
    "history_model_1 = model2.fit(train_x, train_y, epochs=50, batch_size=500, validation_split=0.25)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "94Csl34HDagr",
    "outputId": "4c77540c-c45f-4f07-c32d-921dbcdac454"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 22ms/step - loss: 7.2492 - accuracy: 0.3118 - val_loss: 1.2515 - val_accuracy: 0.3777\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 1.0345 - accuracy: 0.5305 - val_loss: 0.9862 - val_accuracy: 0.6099\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.9835 - accuracy: 0.6135 - val_loss: 0.9627 - val_accuracy: 0.6328\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.9479 - accuracy: 0.6412 - val_loss: 0.9118 - val_accuracy: 0.6397\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.8589 - accuracy: 0.6462 - val_loss: 0.7774 - val_accuracy: 0.6699\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.7601 - accuracy: 0.6603 - val_loss: 0.7243 - val_accuracy: 0.6625\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.7164 - accuracy: 0.6512 - val_loss: 0.6912 - val_accuracy: 0.6525\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.6843 - accuracy: 0.6641 - val_loss: 0.6638 - val_accuracy: 0.7308\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 4ms/step - loss: 0.6566 - accuracy: 0.8426 - val_loss: 0.6370 - val_accuracy: 0.9483\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.6269 - accuracy: 0.9463 - val_loss: 0.6062 - val_accuracy: 0.9597\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5952 - accuracy: 0.9493 - val_loss: 0.5717 - val_accuracy: 0.9625\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.5598 - accuracy: 0.9539 - val_loss: 0.5353 - val_accuracy: 0.9638\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.9559 - val_loss: 0.4989 - val_accuracy: 0.9661\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4891 - accuracy: 0.9589 - val_loss: 0.4651 - val_accuracy: 0.9675\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.4590 - accuracy: 0.9618 - val_loss: 0.4377 - val_accuracy: 0.9693\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.4326 - accuracy: 0.9666 - val_loss: 0.4082 - val_accuracy: 0.9725\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.4039 - accuracy: 0.9682 - val_loss: 0.3851 - val_accuracy: 0.9739\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3855 - accuracy: 0.9685 - val_loss: 0.3699 - val_accuracy: 0.9776\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3713 - accuracy: 0.9721 - val_loss: 0.3586 - val_accuracy: 0.9794\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3601 - accuracy: 0.9737 - val_loss: 0.3491 - val_accuracy: 0.9808\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3512 - accuracy: 0.9762 - val_loss: 0.3404 - val_accuracy: 0.9821\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3442 - accuracy: 0.9762 - val_loss: 0.3345 - val_accuracy: 0.9831\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3361 - accuracy: 0.9791 - val_loss: 0.3266 - val_accuracy: 0.9840\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3297 - accuracy: 0.9801 - val_loss: 0.3195 - val_accuracy: 0.9849\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3237 - accuracy: 0.9785 - val_loss: 0.3141 - val_accuracy: 0.9849\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3177 - accuracy: 0.9818 - val_loss: 0.3090 - val_accuracy: 0.9844\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3123 - accuracy: 0.9812 - val_loss: 0.3032 - val_accuracy: 0.9863\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.3071 - accuracy: 0.9818 - val_loss: 0.2980 - val_accuracy: 0.9867\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.3019 - accuracy: 0.9827 - val_loss: 0.2940 - val_accuracy: 0.9863\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2973 - accuracy: 0.9831 - val_loss: 0.2885 - val_accuracy: 0.9876\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2928 - accuracy: 0.9824 - val_loss: 0.2855 - val_accuracy: 0.9867\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2879 - accuracy: 0.9843 - val_loss: 0.2792 - val_accuracy: 0.9890\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2834 - accuracy: 0.9844 - val_loss: 0.2751 - val_accuracy: 0.9895\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2788 - accuracy: 0.9841 - val_loss: 0.2707 - val_accuracy: 0.9899\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 5ms/step - loss: 0.2746 - accuracy: 0.9844 - val_loss: 0.2668 - val_accuracy: 0.9895\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2702 - accuracy: 0.9846 - val_loss: 0.2620 - val_accuracy: 0.9886\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2659 - accuracy: 0.9858 - val_loss: 0.2574 - val_accuracy: 0.9899\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.2614 - accuracy: 0.9852 - val_loss: 0.2540 - val_accuracy: 0.9908\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2576 - accuracy: 0.9861 - val_loss: 0.2493 - val_accuracy: 0.9895\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 0.2529 - accuracy: 0.9867 - val_loss: 0.2451 - val_accuracy: 0.9904\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2491 - accuracy: 0.9875 - val_loss: 0.2408 - val_accuracy: 0.9908\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2455 - accuracy: 0.9876 - val_loss: 0.2369 - val_accuracy: 0.9913\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 6ms/step - loss: 0.2421 - accuracy: 0.9869 - val_loss: 0.2333 - val_accuracy: 0.9913\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2375 - accuracy: 0.9878 - val_loss: 0.2293 - val_accuracy: 0.9918\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2337 - accuracy: 0.9887 - val_loss: 0.2258 - val_accuracy: 0.9918\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2309 - accuracy: 0.9867 - val_loss: 0.2229 - val_accuracy: 0.9913\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2268 - accuracy: 0.9878 - val_loss: 0.2183 - val_accuracy: 0.9931\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 8ms/step - loss: 0.2234 - accuracy: 0.9898 - val_loss: 0.2151 - val_accuracy: 0.9922\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 7ms/step - loss: 0.2197 - accuracy: 0.9899 - val_loss: 0.2117 - val_accuracy: 0.9922\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 0.2166 - accuracy: 0.9889 - val_loss: 0.2083 - val_accuracy: 0.9922\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "score = model2.evaluate(test_x, test_y)\n",
    "\n",
    "print(f\"모델 2 오차 : {score[0] * 100 : .2f}%\")\n",
    "print(f\"모델 2 정확도 : {score[1] * 100 : .2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s48IPA6fDeGA",
    "outputId": "75b8c934-a686-454c-b256-ee25786891b4"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "117/117 [==============================] - 0s 2ms/step - loss: 0.2111 - accuracy: 0.9920\n",
      "모델 2 오차 :  21.11%\n",
      "모델 2 정확도 :  99.20%\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# model1.save(\"/content/drive/Shareddrives/2023 인공지능 모델링 프로젝트/model/model1.hdf5\")\n",
    "model2.save(\"/content/drive/Shareddrives/2023 인공지능 모델링 프로젝트/model/model2.hdf5\")"
   ],
   "metadata": {
    "id": "g06pvoJQDfdE"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "loss_train = history_model_1.history[\"loss\"]\n",
    "loss_val = history_model_1.history[\"val_loss\"]\n",
    "\n",
    "epoch = range(1, len(loss_val) + 1)\n",
    "\n",
    "plt.plot(epoch, loss_train, \"b-\")\n",
    "plt.xlabel(\"학습 횟수\").set_size(12)\n",
    "plt.ylabel(\"모델 오차\").set_size(12)\n",
    "\n",
    "plt.savefig(\"오차 그래프.png\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "id": "TTZy8HemEIyP",
    "outputId": "4c729b78-84dd-4f6c-f41d-a2bd30193f21"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ],
      "image/png": "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\n"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "bnDn1_-FOCSv"
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
